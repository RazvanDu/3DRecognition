{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import keras.models\n",
    "import trimesh\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from random import seed\n",
    "from random import random\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def read_off(file):\n",
    "    return trimesh.load(file).sample(8192)\n",
    "\n",
    "\n",
    "def normalize(train_data):\n",
    "    current = 0\n",
    "    normalizedSize = 240\n",
    "    new_train_data = []\n",
    "\n",
    "    maxXReal = 0\n",
    "    maxYReal = 0\n",
    "    maxZReal = 0\n",
    "\n",
    "    for model in train_data:\n",
    "        minX = 123123123\n",
    "        minY = 123123123\n",
    "        minZ = 123123123\n",
    "        maxX = -123123123\n",
    "        maxY = -123123123\n",
    "        maxZ = -123123123\n",
    "\n",
    "        for point in model[1]:\n",
    "            minX = min(minX, point[0])\n",
    "            minY = min(minY, point[1])\n",
    "            minZ = min(minZ, point[2])\n",
    "            maxX = max(maxX, point[0])\n",
    "            maxY = max(maxY, point[1])\n",
    "            maxZ = max(maxZ, point[2])\n",
    "\n",
    "        result = []\n",
    "\n",
    "        if maxX - minX >= maxY - minY and maxX - minX >= maxZ - minZ:\n",
    "            divRatio = maxX - minX\n",
    "        elif maxY - minY >= maxX - minX and maxY - minY >= maxZ - minZ:\n",
    "            divRatio = maxY - minY\n",
    "        else:\n",
    "            divRatio = maxZ - minZ\n",
    "\n",
    "        for point in model[1]:\n",
    "            newX = ((point[0] - minX) / divRatio) * normalizedSize\n",
    "            newY = ((point[1] - minY) / divRatio) * normalizedSize\n",
    "            newZ = ((point[2] - minZ) / (maxZ - minZ)) * normalizedSize\n",
    "\n",
    "            maxXReal = max(maxXReal, newX)\n",
    "            maxYReal = max(maxYReal, newY)\n",
    "            maxZReal = max(maxZReal, newZ)\n",
    "\n",
    "            result.append(np.array([newX, newY, newZ]))\n",
    "\n",
    "            # print(str(point[0]) + \" + \" + str(point[1]) + \" + \" + str(point[2]))\n",
    "\n",
    "        new_train_data.append((model[0], np.array(result)))\n",
    "\n",
    "        current += 1\n",
    "\n",
    "        if current % 100 == 0:\n",
    "            print(current)\n",
    "\n",
    "        # print(str(minX) + \" + \" + str(maxX))\n",
    "    return new_train_data\n",
    "\n",
    "\n",
    "def changeView(data):\n",
    "    current = 0\n",
    "    normalizedSize = 240\n",
    "    images = []\n",
    "\n",
    "    for model in data:\n",
    "        slices = np.zeros((normalizedSize*4, normalizedSize*4), 'uint8')\n",
    "        for point in model[1]:\n",
    "            # point_slice = int((point[2] - 0.001) / 20)\n",
    "            # i = int(point_slice / 4)\n",
    "            # j = int(point_slice % 4)\n",
    "            # #targetI = int(point[0] - 0.01 + i * normalizedSize)\n",
    "            # #targetJ = int(point[1] - 0.01 + j * normalizedSize)\n",
    "            # for nextI in range(3):\n",
    "            #     for nextJ in range(3):\n",
    "            #         goI = int(point[0] + nextI - 1 - 0.01)\n",
    "            #         goJ = int(point[1] + nextJ - 1 - 0.01)\n",
    "            #\n",
    "            #         if goI < 0 or goI >= normalizedSize or goJ < 0 or goJ >= normalizedSize:\n",
    "            #             continue\n",
    "            #\n",
    "            #         slices[int(point[0] - 0.01), int(point[1] - 0.01), i] |= (3 << (2 * j))\n",
    "            point_slice = int((point[2] - 0.001) / 15)\n",
    "            i = int(point_slice / 4)\n",
    "            j = int(point_slice % 4)\n",
    "            targetI = int(point[0] - 0.01 + i * normalizedSize)\n",
    "            targetJ = int(point[1] - 0.01 + j * normalizedSize)\n",
    "            for nextI in range(3):\n",
    "                for nextJ in range(3):\n",
    "                    goI = targetI + nextI - 1\n",
    "                    goJ = targetJ + nextJ - 1\n",
    "\n",
    "                    if goI < 0 or goI >= 4*normalizedSize or goJ < 0 or goJ >= 4*normalizedSize:\n",
    "                        continue\n",
    "\n",
    "                    slices[goI, goJ] = 1\n",
    "\n",
    "\n",
    "        images.append((model[0], slices))\n",
    "        current += 1\n",
    "        if current % 100 == 0:\n",
    "            print(current)\n",
    "\n",
    "    return images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_70331/1270175850.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrandom\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_images\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_images\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;31m# img = Image.fromarray(test_images[index][1])\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# img.save('myimg.jpeg')\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_images\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mcmap\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'grey_r'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'test_images' is not defined"
     ]
    }
   ],
   "source": [
    "index = int(random() * len(test_images))\n",
    "print(test_images[index][0])\n",
    "# img = Image.fromarray(test_images[index][1])\n",
    "# img.save('myimg.jpeg')\n",
    "plt.imshow(test_images[index][1],cmap='grey_r')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ModelNet10/chair/train'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_70331/793872944.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mcategory\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mcategories\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m     \u001B[0mfiles_train\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlistdir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mcategory\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\"/train\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mf\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mfiles_train\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'ModelNet10/chair/train'"
     ]
    }
   ],
   "source": [
    "categories = [\"bathtub\", \"bed\", \"chair\", \"desk\", \"dresser\", \"monitor\", \"night_stand\", \"sofa\", \"table\", \"toilet\"]\n",
    "\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "path = 'ModelNet10/'\n",
    "\n",
    "current = 0\n",
    "\n",
    "for category in categories:\n",
    "\n",
    "    files_train = os.listdir(path + category + \"/train\")\n",
    "\n",
    "    for f in files_train:\n",
    "        train_data.append((category, read_off(path + category + \"/train/\" + f)))\n",
    "        current += 1\n",
    "        if current % 100 == 0:\n",
    "            print(current)\n",
    "\n",
    "    files_test = os.listdir(path + category + \"/test\")\n",
    "\n",
    "    for f in files_test:\n",
    "        test_data.append((category, read_off(path + category + \"/test/\" + f)))\n",
    "        current += 1\n",
    "        if current % 100 == 0:\n",
    "            print(current)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "100\n"
     ]
    }
   ],
   "source": "train_data = normalize(train_data)\ntest_data = normalize(test_data)",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "100\n"
     ]
    }
   ],
   "source": "train_images = changeView(train_data)\ntest_images = changeView(test_data)\n\n# # %%\n# random_index = random.randint(0, len(train_images))\n# print(train_data[random_index][0])\n#\n# # %%\n# fig = plt.figure(figsize=(5, 5))\n# ax = fig.add_subplot(111, projection=\"3d\")\n# ax.set_xlim([0, maxXReal])\n# ax.set_ylim([0, maxYReal])\n# ax.set_zlim([0, maxZReal])\n# ax.scatter(train_data[random_index][1][:, 0], train_data[random_index][1][:, 1], train_data[random_index][1][:, 2])\n# ax.view_init(30, 200)\n#\n# # %%\n# plt.imshow(train_images[random_index][1], cmap='gray_r')\n# plt.show()",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": "train_final = np.array([i[1] for i in train_images])\ntrain_labels = np.array([categories.index(l) for l in [i[0] for i in train_images]])",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-06 01:23:15.735138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-06 01:23:15.735682: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-06 01:23:15.736306: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-06 01:23:15.737295: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-06 01:23:15.737497: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-01-06 01:23:15.737684: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-01-06 01:23:15.738600: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-06 01:23:15.739234: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-06 01:23:15.740064: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-01-06 01:23:15.740093: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-01-06 01:23:15.741645: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": "model = tf.keras.Sequential([\n    # tf.keras.layers.Conv2D(60, kernel_size=(3, 3), input_shape=(240*4, 240*4, 1)),\n    # tf.keras.layers.MaxPool2D(pool_size=(8, 8)),\n    # tf.keras.layers.Conv2D(60, kernel_size=(3, 3)),\n    # tf.keras.layers.MaxPool2D(pool_size=(8, 8)), # !!! 2 2\n    tf.keras.layers.Flatten(),\n    # tf.keras.layers.Dropout(0.7),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(64, activation='relu'),\n    #tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(32, activation='relu'),\n    #tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(64, activation='relu'),\n    #tf.keras.layers.Dropout(0.5),\n    #tf.keras.layers.Dense(512, activation='relu'),\n    #tf.keras.layers.Dropout(0.5),\n    #tf.keras.layers.Dense(256, activation='relu'),\n    #tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cgis/ThreeObjectRecognition/research/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 4s 174ms/step - loss: 0.6859 - accuracy: 0.7242\n",
      "Epoch 2/4\n",
      "18/18 [==============================] - 3s 169ms/step - loss: 0.0806 - accuracy: 0.9680\n",
      "Epoch 3/4\n",
      "18/18 [==============================] - 3s 167ms/step - loss: 0.0170 - accuracy: 0.9964\n",
      "Epoch 4/4\n",
      "18/18 [==============================] - 3s 166ms/step - loss: 0.0066 - accuracy: 0.9964\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f35012d1730>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "model.fit(train_final, train_labels, epochs=4)",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_70331/1428512860.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtest_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_acc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_final\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_labels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'\\nTest accuracy:'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_acc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'test_final' is not defined"
     ]
    }
   ],
   "source": "test_loss, test_acc = model.evaluate(test_final, test_labels, verbose=2)\n\nprint('\\nTest accuracy:', test_acc)",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": "model.save(\"first.h5\")\ndel model",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": "i = 0",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_70331/3081531301.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mwhile\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0mi\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_final\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_labels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_final\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_labels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": "while 1:\n    i += 1\n    print(i)\n    print(train_final.shape, train_labels.shape)\n    model.fit(train_final, train_labels, epochs=1)\n    test_loss, test_acc = model.evaluate(test_final, test_labels, verbose=2)\n    print('Test accuracy:', test_acc, '\\n')",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": "test_loss, test_acc = model.evaluate(test_final, test_labels, verbose=2)\nprint('Test accuracy:', test_acc, '\\n')",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": "model.save(\"third.h5\")\nnp.save('train_final_third.npy', train_final)\nnp.save('test_final_third.npy', test_final)\nnp.save('train_labels_third.npy', train_labels)\nnp.save('test_labels_third.npy', test_labels)",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": "model = keras.models.load_model(\"third.h5\")\ntrain_final = np.load(\"train_final_third.npy\")\ntest_final = np.load(\"test_final_third.npy\")\ntrain_labels = np.load(\"train_labels_third.npy\")\ntest_labels = np.load(\"test_labels_third.npy\")",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}